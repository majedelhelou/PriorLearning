# PriorLearning

### 1. Dependencies
* Numpy
* Matplotlib
* OpenCV for Python
* [HDF5 for Python](http://www.h5py.org/)
* PyTorch

### 2. Reproduce results
To train the models you have two possibilities:
- Run the `train.py` directly with the desired parameters. The list of possible parameters is printed when the file is run with the `--help` argument. Note the the only two supported optimizers are `SGD` and `Adam`, and the `--augmentation` argument supports either `no` data augmentation, `standard` or `vae`. We recommend writing a script to automate this process when running on multiple dataset sizes.
- Run the `train_test_model.sh` script to automatically get the results for the same dataset sizes we used. This scripts supports the following arguments: `-c` which should be set to `true` to create the h5py dataset; `-s` to set the seed; `-o` to specify the optimizer; `-lr` to specify the learning rate; `-b` to specify the batch size; `-k` to specify the sigma parameter of the gaussian kernel used to blur the images; `-d` to specify the number of layers in the model; `-a` to specify the type of data augmentation. Note that if script displays the 'bad interpreter ...' message you can run this command to fix the problem: `sed -i 's/\r//' train_test_model.sh`.

### 3. Visualize the results
You can use the `Results.ipynb` notebook to visualize the results. You need to have the 'logs' folder at the same location as your notebook for it to work. The code to generate all the graphs used in the report is on the notebook and can be used as is as long as you have run the code with the parameters you want to visualize.

If you want to run all the experiments you can simply run the `experiments.sh` script but the running time will be very long!

### 4. Visualize the VAE
To get images generated by the Variational AutoEncoder, you can create a 'vae_generated' folder and simply run the `vae.py` and/or `vae_alernate.py` files. Some generated examples such as the ones used in the report will be saved in that folder. Note that the h5py dataset should already be generated with the default settings (patch size set to 64 and stride to 32) for this to work as the vae doesn't create the dataset and doesn't take parameters as of now.

### 5. Unblur images
To blur and then deblurr some test images you can use the `test.py` file directly. The images will be saved in the 'saved_images' folder. You can specify the number of images you want with the `--num_images` argument.

### 6. Baseline
To reproduce the baseline results, simply run the `baseline.py` file. This will print the mean PSNR from the baseline deblurring and save some example images in the 'saved_images' folder.
